{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 13: Feedback Loops.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVaMLvQ29qdq"
      },
      "source": [
        "# Chapter 13: Feedback Loops\n",
        "\n",
        "Feedback Loops are crucial for holding or improving the deployed model's performance. At this point it is extremely important to have the rest of the pipeline set up robustly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDzKMeP0_LoT"
      },
      "source": [
        "## Explicit and Implicit Feedback\n",
        "\n",
        "Implicit feedback is where people's actions in their normaal usage of a product give the model feedback - e.g., by buying something suggested by a recommnder system or by watching a suggested movie.<br>\n",
        "Explicit feedback is where a user gives some direct input on a prediction - e.g., giving thumbs-up or thumbs-down to a recommendation or correcting a prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oThCHRpnAKhU"
      },
      "source": [
        "### The Data Flywheel\n",
        "\n",
        "In the case where you have a lot of unlabelled data and need to collect more labels, the data flywheel concept is especially useful. This data flywheel allows you to grow your training dataset by setting up an initial model using preexisting data from a product, hand-labelled data, or public data. By collecting feedback on the intiial model from users, you can label the data, which improves the model predictions and thus attracts more users to the product, who label more data, and so on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfPxO4k1Bsxg"
      },
      "source": [
        "## Designing Patterns for Collecting Feedback\n",
        "\n",
        "Your choice of method will depend on a few things:\n",
        " - The businees problem you are traying to solve\n",
        " - The type and design of the app or product\n",
        " - The type of machine learning model: Classification, Recommender System, etc.\n",
        "\n",
        "\n",
        "Different options for collecting feedback:\n",
        " - Users take some action as a result of the prediction\n",
        " - Users rate the quality of the prediction\n",
        " - Users correct the prediction\n",
        " - Crowdsourcing the annotations\n",
        " - Expert annotations\n",
        " - Producing feedback automatically"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6XLKMJEC74a"
      },
      "source": [
        "## How to Track Feedback Loop\n",
        "\n",
        "The key concept is that every prediction should receive a tracking ID. This can be implemented with some kind of prediction register in which each prediction is stored along with a tracking ID.The prediction an the ID are passed to the application and then the prediction is show to the user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgzvgC0UDd3v"
      },
      "source": [
        "### Tracking Explicit Feedback\n",
        "\n",
        "If the system is collecting explicit feedback, as described previously, there are two possibilities for how to track it:\n",
        " - Binary Feedback\n",
        " - Reclassification or Correction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troiitLJDxgh"
      },
      "source": [
        "### Tracking Implicit Feedback\n",
        "\n",
        "Implicit feedback generate binary feedback."
      ]
    }
  ]
}